{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b5f65da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "class SeqDataset(object):\n",
    "\n",
    "    def __init__(self, ids, features, labels, groups, wordRanges, truePos):\n",
    "        '''\n",
    "        ids are ids of candidate sequences\n",
    "\n",
    "        each row of features is 13 features corresponding to the following:\n",
    "        feature_0: pred_end - pred_start so length of span -1\n",
    "        feature_1: normalized start position (normalized by number of words)\n",
    "        feature_2: normalized end position (normalized by number of words)\n",
    "        feature_4-10: 7 evenly spaced quantiles of the distribution of relevant class probabilities for this sequence\n",
    "        feature_11: The probability that words on either edge of the current sub-sequence belong to the class of interest\n",
    "        feature_12: The probability that the first word corresponds to a 'B'-egin token\n",
    "\n",
    "        labels are binary labels corresponding to whether the candidate sequence is an exact match to a true span\n",
    "\n",
    "        wordRanges are the start and end (inclusive on both sides) indices of the candidate sequence\n",
    "\n",
    "        truePos are binary labels corresponding to whether the candidate sequence would be considered a true positive (>0.5 overlap)\n",
    "\n",
    "        '''\n",
    "        self.features = np.array(features, dtype=np.float32)\n",
    "        self.labels = np.array(labels)\n",
    "        self.groups = np.array(groups, dtype=np.int16)\n",
    "        self.wordRanges = np.array(wordRanges, dtype=np.int16)\n",
    "        self.truePos = np.array(truePos)\n",
    "        self.ids=ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a01beb17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "disc_types = ['Evidence','Claim','Lead','Position','Counterclaim','Rebuttal','Concluding Statement']\n",
    "\n",
    "dfs = []\n",
    "\n",
    "folder= 'cache' #put pickle files in this folder\n",
    "for fold in range(8):\n",
    "    with open(f'{folder}/valid_seqds_fold{fold}.p','rb') as f:\n",
    "        seqdataset=pickle.load(f)\n",
    "        \n",
    "        for disc_type in disc_types:\n",
    "            x = seqdataset[disc_type]\n",
    "\n",
    "            df = pd.DataFrame()\n",
    "            df[[f\"f_{i}\" for i in range(x.features.shape[1])]] = x.features\n",
    "            df[\"id\"] = x.ids\n",
    "            df[\"class\"] = disc_type\n",
    "            df[[\"begin\", \"end\"]] = x.wordRanges\n",
    "            df[\"kfold\"] = fold\n",
    "            \n",
    "            dfs.append(df)\n",
    "            \n",
    "            \n",
    "len_features = x.features.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9162383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35724267, 31)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>...</th>\n",
       "      <th>f_21</th>\n",
       "      <th>f_22</th>\n",
       "      <th>f_23</th>\n",
       "      <th>f_24</th>\n",
       "      <th>f_25</th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.183223</td>\n",
       "      <td>0.185430</td>\n",
       "      <td>0.994907</td>\n",
       "      <td>0.994907</td>\n",
       "      <td>0.994907</td>\n",
       "      <td>0.994907</td>\n",
       "      <td>0.994907</td>\n",
       "      <td>0.994907</td>\n",
       "      <td>0.994907</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064025</td>\n",
       "      <td>0.024539</td>\n",
       "      <td>0.018976</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>0.120611</td>\n",
       "      <td>4AB030046F42</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>83</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.183223</td>\n",
       "      <td>0.187638</td>\n",
       "      <td>0.994907</td>\n",
       "      <td>0.995471</td>\n",
       "      <td>0.996034</td>\n",
       "      <td>0.996597</td>\n",
       "      <td>0.997161</td>\n",
       "      <td>0.997724</td>\n",
       "      <td>0.998287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064025</td>\n",
       "      <td>0.024539</td>\n",
       "      <td>0.018976</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>0.120611</td>\n",
       "      <td>4AB030046F42</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>83</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.183223</td>\n",
       "      <td>0.189845</td>\n",
       "      <td>0.994907</td>\n",
       "      <td>0.996034</td>\n",
       "      <td>0.997161</td>\n",
       "      <td>0.998287</td>\n",
       "      <td>0.998625</td>\n",
       "      <td>0.998963</td>\n",
       "      <td>0.999300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064025</td>\n",
       "      <td>0.024539</td>\n",
       "      <td>0.018976</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>0.120611</td>\n",
       "      <td>4AB030046F42</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>83</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.183223</td>\n",
       "      <td>0.192053</td>\n",
       "      <td>0.994907</td>\n",
       "      <td>0.996597</td>\n",
       "      <td>0.998287</td>\n",
       "      <td>0.998794</td>\n",
       "      <td>0.999300</td>\n",
       "      <td>0.999482</td>\n",
       "      <td>0.999665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064025</td>\n",
       "      <td>0.024539</td>\n",
       "      <td>0.018976</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>0.120611</td>\n",
       "      <td>4AB030046F42</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>83</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.183223</td>\n",
       "      <td>0.194260</td>\n",
       "      <td>0.994907</td>\n",
       "      <td>0.997161</td>\n",
       "      <td>0.998625</td>\n",
       "      <td>0.999300</td>\n",
       "      <td>0.999502</td>\n",
       "      <td>0.999624</td>\n",
       "      <td>0.999665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064025</td>\n",
       "      <td>0.024539</td>\n",
       "      <td>0.018976</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>0.120611</td>\n",
       "      <td>4AB030046F42</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>83</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   f_0       f_1       f_2       f_3       f_4       f_5       f_6       f_7  \\\n",
       "0  1.0  0.183223  0.185430  0.994907  0.994907  0.994907  0.994907  0.994907   \n",
       "1  2.0  0.183223  0.187638  0.994907  0.995471  0.996034  0.996597  0.997161   \n",
       "2  3.0  0.183223  0.189845  0.994907  0.996034  0.997161  0.998287  0.998625   \n",
       "3  4.0  0.183223  0.192053  0.994907  0.996597  0.998287  0.998794  0.999300   \n",
       "4  5.0  0.183223  0.194260  0.994907  0.997161  0.998625  0.999300  0.999502   \n",
       "\n",
       "        f_8       f_9  ...      f_21      f_22      f_23      f_24      f_25  \\\n",
       "0  0.994907  0.994907  ...  0.064025  0.024539  0.018976  0.002926  0.120611   \n",
       "1  0.997724  0.998287  ...  0.064025  0.024539  0.018976  0.002926  0.120611   \n",
       "2  0.998963  0.999300  ...  0.064025  0.024539  0.018976  0.002926  0.120611   \n",
       "3  0.999482  0.999665  ...  0.064025  0.024539  0.018976  0.002926  0.120611   \n",
       "4  0.999624  0.999665  ...  0.064025  0.024539  0.018976  0.002926  0.120611   \n",
       "\n",
       "             id     class  begin  end  kfold  \n",
       "0  4AB030046F42  Evidence     83   84      0  \n",
       "1  4AB030046F42  Evidence     83   85      0  \n",
       "2  4AB030046F42  Evidence     83   86      0  \n",
       "3  4AB030046F42  Evidence     83   87      0  \n",
       "4  4AB030046F42  Evidence     83   88      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_df = pd.concat(dfs)\n",
    "print(oof_df.shape)\n",
    "oof_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bccb3df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>155306</th>\n",
       "      <th>1944845</th>\n",
       "      <th>281859</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f_0</th>\n",
       "      <td>178.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.393365</td>\n",
       "      <td>0.206349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_2</th>\n",
       "      <td>0.364754</td>\n",
       "      <td>0.763033</td>\n",
       "      <td>0.306471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_3</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.063316</td>\n",
       "      <td>0.444897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_4</th>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.09902</td>\n",
       "      <td>0.484587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_5</th>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.110496</td>\n",
       "      <td>0.508487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_6</th>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.584912</td>\n",
       "      <td>0.94751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_7</th>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.722076</td>\n",
       "      <td>0.957281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_8</th>\n",
       "      <td>0.073677</td>\n",
       "      <td>0.953462</td>\n",
       "      <td>0.961175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_9</th>\n",
       "      <td>0.976568</td>\n",
       "      <td>0.970241</td>\n",
       "      <td>0.967838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.488795</td>\n",
       "      <td>0.677597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_11</th>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.552889</td>\n",
       "      <td>0.902134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.461277</td>\n",
       "      <td>0.675871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_13</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.54066</td>\n",
       "      <td>0.648468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_14</th>\n",
       "      <td>0.974121</td>\n",
       "      <td>0.483154</td>\n",
       "      <td>0.312744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_15</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.951219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_17</th>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.329268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_18</th>\n",
       "      <td>0.004613</td>\n",
       "      <td>0.023944</td>\n",
       "      <td>0.00486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_19</th>\n",
       "      <td>0.590981</td>\n",
       "      <td>0.384558</td>\n",
       "      <td>0.664168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_20</th>\n",
       "      <td>0.074113</td>\n",
       "      <td>0.332557</td>\n",
       "      <td>0.133048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_21</th>\n",
       "      <td>0.029248</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.06477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_22</th>\n",
       "      <td>0.046254</td>\n",
       "      <td>0.125407</td>\n",
       "      <td>0.01622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_23</th>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.019541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_24</th>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00087</td>\n",
       "      <td>0.015776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f_25</th>\n",
       "      <td>0.190493</td>\n",
       "      <td>0.076494</td>\n",
       "      <td>0.08128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>F6DA09C9C0C1</td>\n",
       "      <td>0949D328CAC8</td>\n",
       "      <td>DBE16C234CF3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>Lead</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>begin</th>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end</th>\n",
       "      <td>178</td>\n",
       "      <td>161</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kfold</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            155306        1944845       281859 \n",
       "f_0           178.0          78.0          82.0\n",
       "f_1             0.0      0.393365      0.206349\n",
       "f_2        0.364754      0.763033      0.306471\n",
       "f_3        0.000007      0.063316      0.444897\n",
       "f_4        0.000009       0.09902      0.484587\n",
       "f_5        0.000013      0.110496      0.508487\n",
       "f_6        0.000069      0.584912       0.94751\n",
       "f_7        0.000243      0.722076      0.957281\n",
       "f_8        0.073677      0.953462      0.961175\n",
       "f_9        0.976568      0.970241      0.967838\n",
       "f_10            0.0      0.488795      0.677597\n",
       "f_11       0.000009      0.552889      0.902134\n",
       "f_12            0.0      0.461277      0.675871\n",
       "f_13        0.00001       0.54066      0.648468\n",
       "f_14       0.974121      0.483154      0.312744\n",
       "f_15       0.000003      0.000148      0.000107\n",
       "f_16            0.0      0.115385      0.951219\n",
       "f_17       0.966292      0.179487      0.329268\n",
       "f_18       0.004613      0.023944       0.00486\n",
       "f_19       0.590981      0.384558      0.664168\n",
       "f_20       0.074113      0.332557      0.133048\n",
       "f_21       0.029248      0.000208       0.06477\n",
       "f_22       0.046254      0.125407       0.01622\n",
       "f_23       0.000088      0.000799      0.019541\n",
       "f_24        0.00011       0.00087      0.015776\n",
       "f_25       0.190493      0.076494       0.08128\n",
       "id     F6DA09C9C0C1  0949D328CAC8  DBE16C234CF3\n",
       "class          Lead      Evidence      Evidence\n",
       "begin             0            83           169\n",
       "end             178           161           251\n",
       "kfold             2             5             7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_df.sample(3, random_state=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96d14cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144293, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>230.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>313.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>402.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>759.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  discourse_id  discourse_start  discourse_end  \\\n",
       "0  423A1CA112E2  1.622628e+12              8.0          229.0   \n",
       "1  423A1CA112E2  1.622628e+12            230.0          312.0   \n",
       "2  423A1CA112E2  1.622628e+12            313.0          401.0   \n",
       "3  423A1CA112E2  1.622628e+12            402.0          758.0   \n",
       "4  423A1CA112E2  1.622628e+12            759.0          886.0   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Modern humans today are always on their phone....           Lead   \n",
       "1  They are some really bad consequences when stu...       Position   \n",
       "2  Some certain areas in the United States ban ph...       Evidence   \n",
       "3  When people have phones, they know about certa...       Evidence   \n",
       "4  Driving is one of the way how to get around. P...          Claim   \n",
       "\n",
       "  discourse_type_num                                   predictionstring  kfold  \n",
       "0             Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...      1  \n",
       "1         Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59      1  \n",
       "2         Evidence 1    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75      1  \n",
       "3         Evidence 2  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...      1  \n",
       "4            Claim 1  139 140 141 142 143 144 145 146 147 148 149 15...      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_df = pd.read_csv(\"../train_folds.csv\")\n",
    "print(gt_df.shape)\n",
    "gt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf18d5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35724267/35724267 [01:34<00:00, 376738.62it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "ps = []\n",
    "\n",
    "for begin, end in tqdm(list(zip(oof_df[\"begin\"].values, oof_df[\"end\"].values))):\n",
    "    #ps.append(\" \".join([str(int(x)) for x in np.arange(begin, end)]))\n",
    "    ps.append(f\"{begin} {end-1}\")\n",
    "oof_df[\"predictionstring\"] = ps    \n",
    "    \n",
    "#ps = []\n",
    "\n",
    "# for begin, end in tqdm(list(zip(gt_df[\"begin\"].values, gt_df[\"end\"].values))):\n",
    "#     #ps.append(\" \".join([str(int(x)) for x in np.arange(begin, end)]))\n",
    "#     ps.append(f\"{begin} {end}\")    \n",
    "# gt_df[\"predictionstring\"] = ps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5101f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7b8cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Rob Mulla @robikscube\n",
    "# https://www.kaggle.com/robikscube/student-writing-competition-twitch\n",
    "def calc_overlap(row):\n",
    "    \"\"\"\n",
    "    Calculates the overlap between prediction and\n",
    "    ground truth and overlap percentages used for determining\n",
    "    true positives.\n",
    "    \"\"\"\n",
    "    set_pred = set(row.predictionstring_pred.split(' '))\n",
    "    set_gt = set(row.predictionstring_gt.split(' '))\n",
    "    # Length of each and intersection\n",
    "    len_gt = len(set_gt)\n",
    "    len_pred = len(set_pred)\n",
    "    inter = len(set_gt.intersection(set_pred))\n",
    "    overlap_1 = inter / len_gt\n",
    "    overlap_2 = inter/ len_pred\n",
    "    return [overlap_1, overlap_2]\n",
    "\n",
    "\n",
    "def score_feedback_comp(pred_df, gt_df):\n",
    "    \"\"\"\n",
    "    A function that scores for the kaggle\n",
    "        Student Writing Competition\n",
    "\n",
    "    Uses the steps in the evaluation page here:\n",
    "        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n",
    "    \"\"\"\n",
    "    gt_df = gt_df[['id','discourse_type','predictionstring']]         .reset_index(drop=True).copy()\n",
    "    pred_df = pred_df[['id','class','predictionstring']]         .reset_index(drop=True).copy()\n",
    "    pred_df['pred_id'] = pred_df.index\n",
    "    gt_df['gt_id'] = gt_df.index\n",
    "    # Step 1. all ground truths and predictions for a given class are compared.\n",
    "    joined = pred_df.merge(gt_df,\n",
    "                           left_on=['id','class'],\n",
    "                           right_on=['id','discourse_type'],\n",
    "                           how='outer',\n",
    "                           suffixes=('_pred','_gt')\n",
    "                          )\n",
    "    joined['predictionstring_gt'] = joined['predictionstring_gt'].fillna(' ')\n",
    "    joined['predictionstring_pred'] = joined['predictionstring_pred'].fillna(' ')\n",
    "\n",
    "    joined['overlaps'] = joined.apply(calc_overlap, axis=1)\n",
    "\n",
    "    # 2. If the overlap between the ground truth and prediction is >= 0.5,\n",
    "    # and the overlap between the prediction and the ground truth >= 0.5,\n",
    "    # the prediction is a match and considered a true positive.\n",
    "    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n",
    "    joined['overlap1'] = joined['overlaps'].apply(lambda x: eval(str(x))[0])\n",
    "    joined['overlap2'] = joined['overlaps'].apply(lambda x: eval(str(x))[1])\n",
    "\n",
    "\n",
    "    joined['potential_TP'] = (joined['overlap1'] >= 0.5) & (joined['overlap2'] >= 0.5)\n",
    "    joined['max_overlap'] = joined[['overlap1','overlap2']].max(axis=1)\n",
    "    tp_pred_ids = joined.query('potential_TP')         .sort_values('max_overlap', ascending=False)         .groupby(['id','predictionstring_gt']).first()['pred_id'].values\n",
    "\n",
    "    # 3. Any unmatched ground truths are false negatives\n",
    "    # and any unmatched predictions are false positives.\n",
    "    fp_pred_ids = [p for p in joined['pred_id'].unique() if p not in tp_pred_ids]\n",
    "\n",
    "    matched_gt_ids = joined.query('potential_TP')['gt_id'].unique()\n",
    "    unmatched_gt_ids = [c for c in joined['gt_id'].unique() if c not in matched_gt_ids]\n",
    "\n",
    "    # Get numbers of each type\n",
    "    TP = len(tp_pred_ids)\n",
    "    FP = len(fp_pred_ids)\n",
    "    FN = len(unmatched_gt_ids)\n",
    "    #calc microf1\n",
    "    my_f1_score = TP / (TP + 0.5*(FP+FN))\n",
    "    return my_f1_score\n",
    "\n",
    "def calc_overlap_shujun(pred, gt):\n",
    "    \"\"\"\n",
    "    Calculates if the overlap between prediction and\n",
    "    ground truth is enough fora potential True positive\n",
    "    \"\"\"\n",
    "    try:\n",
    "        g1=pred[1]+1-gt[0]\n",
    "        g2=gt[1]+1-pred[0]\n",
    "        l1=pred[1]-pred[0]+1\n",
    "        l2=gt[1]-gt[0]+1\n",
    "        #print(g1,g2)\n",
    "        if g1*g2>=0:\n",
    "            #g1=abs(g1)+1\n",
    "            #g2=abs(g2)+1\n",
    "            inter=min((g1,g2,l1,l2))#/max((g1,g2,l1,l2))\n",
    "            overlap_1=inter/l1\n",
    "            overlap_2=inter/l2\n",
    "            return overlap_1 >= 0.5 and overlap_2 >= 0.5\n",
    "        else:\n",
    "            return False\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "\n",
    "def score_feedback_comp_micro_shujun(pred_df, gt_df, discourse_type):\n",
    "    \"\"\"\n",
    "    A function that scores for the kaggle\n",
    "        Student Writing Competition\n",
    "\n",
    "    Uses the steps in the evaluation page here:\n",
    "        https://www.kaggle.com/c/feedback-prize-2021/overview/evaluation\n",
    "    \"\"\"\n",
    "    gt_df = gt_df.loc[gt_df['discourse_type'] == discourse_type,\n",
    "                      ['id', 'predictionstring']].reset_index(drop=True)\n",
    "    pred_df = pred_df.loc[pred_df['class'] == discourse_type,\n",
    "                      ['id', 'predictionstring']].reset_index(drop=True)\n",
    "    pred_df['pred_id'] = pred_df.index\n",
    "    gt_df['gt_id'] = gt_df.index\n",
    "    pred_df['predictionstring'] = [(int(pred.split(' ')[0]),int(pred.split(' ')[-1])) for pred in pred_df['predictionstring']]\n",
    "    gt_df['predictionstring'] = [(int(pred.split(' ')[0]),int(pred.split(' ')[-1])) for pred in gt_df['predictionstring']]\n",
    "\n",
    "\n",
    "#     print(pred_df[pred_df['predictionstring']!=pred_df['predictionstring']])\n",
    "#     exit()\n",
    "    #gt_strings=\n",
    "\n",
    "    # Step 1. all ground truths and predictions for a given class are compared.\n",
    "    joined = pred_df.merge(gt_df,\n",
    "                           left_on='id',\n",
    "                           right_on='id',\n",
    "                           how='outer',\n",
    "                           suffixes=('_pred','_gt')\n",
    "                          )\n",
    "    overlaps = [calc_overlap_shujun(*args) for args in zip(list(joined.predictionstring_pred),\n",
    "                                                     list(joined.predictionstring_gt))]\n",
    "\n",
    "    # 2. If the overlap between the ground truth and prediction is >= 0.5,\n",
    "    # and the overlap between the prediction and the ground truth >= 0.5,\n",
    "    # the prediction is a match and considered a true positive.\n",
    "    # If multiple matches exist, the match with the highest pair of overlaps is taken.\n",
    "    # we don't need to compute the match to compute the score\n",
    "    TP = joined.loc[overlaps]['gt_id'].nunique()\n",
    "\n",
    "    # 3. Any unmatched ground truths are false negatives\n",
    "    # and any unmatched predictions are false positives.\n",
    "    TPandFP = len(pred_df)\n",
    "    TPandFN = len(gt_df)\n",
    "\n",
    "    #calc microf1\n",
    "    my_f1_score = 2*TP / (TPandFP + TPandFN)\n",
    "    return my_f1_score\n",
    "\n",
    "def score_feedback_comp_shujun(pred_df, gt_df, return_class_scores=False):\n",
    "    class_scores = {}\n",
    "    for discourse_type in gt_df.discourse_type.unique():\n",
    "        class_score = score_feedback_comp_micro_shujun(pred_df, gt_df, discourse_type)\n",
    "        class_scores[discourse_type] = class_score\n",
    "    f1 = np.mean([v for v in class_scores.values()])\n",
    "    if return_class_scores:\n",
    "        return f1, class_scores\n",
    "    return f1\n",
    "\n",
    "sample_df = oof_df[oof_df[\"f_7\"] > 0.9999].reset_index(drop=True)\n",
    "print(sample_df.shape)\n",
    "\n",
    "score_feedback_comp_shujun(sample_df, gt_df, return_class_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7d4f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_df[\"idx\"] = np.arange(oof_df.shape[0])\n",
    "\n",
    "eval_df = oof_df[[\"idx\", \"id\", \"class\", \"predictionstring\"]].merge(gt_df[[\"id\", \"discourse_type\", \"predictionstring\"]].rename(columns={\"predictionstring\": \"gt_ps\",\n",
    "                                                                                          \"discourse_type\": 'class'}), \n",
    "                      how=\"left\", on=[\"id\", \"class\"])\n",
    "eval_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c06517",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f393f314",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_overlap_shujun_min(pred, gt):\n",
    "    \"\"\"\n",
    "    Calculates if the overlap between prediction and\n",
    "    ground truth is enough fora potential True positive\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pred=[int(pred.split()[0]),int(pred.split()[-1])]\n",
    "        gt=[int(gt.split()[0]),int(gt.split()[-1])]\n",
    "        g1=pred[1]+1-gt[0]\n",
    "        g2=gt[1]+1-pred[0]\n",
    "        l1=pred[1]-pred[0]+1\n",
    "        l2=gt[1]-gt[0]+1\n",
    "        #print(g1,g2)\n",
    "        if g1*g2>=0:\n",
    "            #g1=abs(g1)+1\n",
    "            #g2=abs(g2)+1\n",
    "            inter=min((g1,g2,l1,l2))#/max((g1,g2,l1,l2))\n",
    "            overlap_1=inter/l1\n",
    "            overlap_2=inter/l2\n",
    "            #return overlap_1 >= 0.5 and overlap_2 >= 0.5\n",
    "            return min(overlap_1,overlap_2)\n",
    "        else:\n",
    "            return 0\n",
    "    except:\n",
    "        return 0 \n",
    "def calc_overlap(predictionstring, gt_ps):\n",
    "\n",
    "    set_pred = set(str(predictionstring).split(\" \"))\n",
    "    set_gt = set(str(gt_ps).split(\" \"))\n",
    "    # Length of each and intersection\n",
    "    len_gt = len(set_gt)\n",
    "    len_pred = len(set_pred)\n",
    "    inter = len(set_gt.intersection(set_pred))\n",
    "    overlap_1 = inter / len_gt\n",
    "    overlap_2 = inter / len_pred\n",
    "    return min(overlap_1, overlap_2)\n",
    "\n",
    "    \n",
    "    \n",
    "overlap = []\n",
    "\n",
    "for predictionstring, gt_ps in tqdm(list(zip(eval_df[\"predictionstring\"].values, eval_df[\"gt_ps\"].values))):\n",
    "    #break\n",
    "    overlap.append(calc_overlap_shujun_min(predictionstring, gt_ps))\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da97300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df[\"overlap\"] = overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6ba2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = eval_df.groupby(\"idx\")[\"overlap\"].max().reset_index()\n",
    "eval_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31bd7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1eb5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea21fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_df.head()[\"idx\"], oof_df.tail()[\"idx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa0e1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_df[\"overlap\"] = eval_df[\"overlap\"].values\n",
    "\n",
    "oof_df[\"overlap\"].fillna(0.0, inplace=True)\n",
    "\n",
    "oof_df[\"overlap\"].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aecff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_df.to_parquet(f\"{folder}/new_oof_shujun_overlap_calc.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84ace2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
