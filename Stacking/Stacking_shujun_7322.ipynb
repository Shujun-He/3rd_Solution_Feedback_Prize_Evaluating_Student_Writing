{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd130934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31992957, 42)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>...</th>\n",
       "      <th>f_32</th>\n",
       "      <th>f_33</th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>kfold</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>idx</th>\n",
       "      <th>overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.183223</td>\n",
       "      <td>0.185430</td>\n",
       "      <td>0.996201</td>\n",
       "      <td>0.996201</td>\n",
       "      <td>0.996201</td>\n",
       "      <td>0.996201</td>\n",
       "      <td>0.996201</td>\n",
       "      <td>0.996201</td>\n",
       "      <td>0.996201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790287</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>4AB030046F42</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>83</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>0.011628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.183223</td>\n",
       "      <td>0.187638</td>\n",
       "      <td>0.996201</td>\n",
       "      <td>0.996581</td>\n",
       "      <td>0.996961</td>\n",
       "      <td>0.997341</td>\n",
       "      <td>0.997721</td>\n",
       "      <td>0.998101</td>\n",
       "      <td>0.998481</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790287</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>4AB030046F42</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>83</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>83 84</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.183223</td>\n",
       "      <td>0.189845</td>\n",
       "      <td>0.996201</td>\n",
       "      <td>0.996961</td>\n",
       "      <td>0.997721</td>\n",
       "      <td>0.998481</td>\n",
       "      <td>0.998793</td>\n",
       "      <td>0.999105</td>\n",
       "      <td>0.999417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790287</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>4AB030046F42</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>83</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>83 84 85</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.183223</td>\n",
       "      <td>0.192053</td>\n",
       "      <td>0.996201</td>\n",
       "      <td>0.997341</td>\n",
       "      <td>0.998481</td>\n",
       "      <td>0.998949</td>\n",
       "      <td>0.999417</td>\n",
       "      <td>0.999611</td>\n",
       "      <td>0.999805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790287</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>4AB030046F42</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>83</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>83 84 85 86</td>\n",
       "      <td>3</td>\n",
       "      <td>0.046512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.183223</td>\n",
       "      <td>0.194260</td>\n",
       "      <td>0.996201</td>\n",
       "      <td>0.997721</td>\n",
       "      <td>0.998793</td>\n",
       "      <td>0.999417</td>\n",
       "      <td>0.999583</td>\n",
       "      <td>0.999712</td>\n",
       "      <td>0.999805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.790287</td>\n",
       "      <td>0.668874</td>\n",
       "      <td>4AB030046F42</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>83</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>83 84 85 86 87</td>\n",
       "      <td>4</td>\n",
       "      <td>0.058140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   f_0       f_1       f_2       f_3       f_4       f_5       f_6       f_7  \\\n",
       "0  1.0  0.183223  0.185430  0.996201  0.996201  0.996201  0.996201  0.996201   \n",
       "1  2.0  0.183223  0.187638  0.996201  0.996581  0.996961  0.997341  0.997721   \n",
       "2  3.0  0.183223  0.189845  0.996201  0.996961  0.997721  0.998481  0.998793   \n",
       "3  4.0  0.183223  0.192053  0.996201  0.997341  0.998481  0.998949  0.999417   \n",
       "4  5.0  0.183223  0.194260  0.996201  0.997721  0.998793  0.999417  0.999583   \n",
       "\n",
       "        f_8       f_9  ...      f_32      f_33            id     class  begin  \\\n",
       "0  0.996201  0.996201  ...  0.790287  0.668874  4AB030046F42  Evidence     83   \n",
       "1  0.998101  0.998481  ...  0.790287  0.668874  4AB030046F42  Evidence     83   \n",
       "2  0.999105  0.999417  ...  0.790287  0.668874  4AB030046F42  Evidence     83   \n",
       "3  0.999611  0.999805  ...  0.790287  0.668874  4AB030046F42  Evidence     83   \n",
       "4  0.999712  0.999805  ...  0.790287  0.668874  4AB030046F42  Evidence     83   \n",
       "\n",
       "   end  kfold  predictionstring  idx   overlap  \n",
       "0   84      0                83    0  0.011628  \n",
       "1   85      0             83 84    1  0.023256  \n",
       "2   86      0          83 84 85    2  0.034884  \n",
       "3   87      0       83 84 85 86    3  0.046512  \n",
       "4   88      0    83 84 85 86 87    4  0.058140  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "N_FOLDS = 5\n",
    "\n",
    "oof_df = pd.read_parquet('cache/new_oof_ensemble.parquet')\n",
    "print(oof_df.shape)\n",
    "\n",
    "oof_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba70a9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(144293, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>discourse_start</th>\n",
       "      <th>discourse_end</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_type_num</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>8.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>Modern humans today are always on their phone....</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Lead 1</td>\n",
       "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>230.0</td>\n",
       "      <td>312.0</td>\n",
       "      <td>They are some really bad consequences when stu...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Position 1</td>\n",
       "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>313.0</td>\n",
       "      <td>401.0</td>\n",
       "      <td>Some certain areas in the United States ban ph...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 1</td>\n",
       "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>402.0</td>\n",
       "      <td>758.0</td>\n",
       "      <td>When people have phones, they know about certa...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Evidence 2</td>\n",
       "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>423A1CA112E2</td>\n",
       "      <td>1.622628e+12</td>\n",
       "      <td>759.0</td>\n",
       "      <td>886.0</td>\n",
       "      <td>Driving is one of the way how to get around. P...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Claim 1</td>\n",
       "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  discourse_id  discourse_start  discourse_end  \\\n",
       "0  423A1CA112E2  1.622628e+12              8.0          229.0   \n",
       "1  423A1CA112E2  1.622628e+12            230.0          312.0   \n",
       "2  423A1CA112E2  1.622628e+12            313.0          401.0   \n",
       "3  423A1CA112E2  1.622628e+12            402.0          758.0   \n",
       "4  423A1CA112E2  1.622628e+12            759.0          886.0   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Modern humans today are always on their phone....           Lead   \n",
       "1  They are some really bad consequences when stu...       Position   \n",
       "2  Some certain areas in the United States ban ph...       Evidence   \n",
       "3  When people have phones, they know about certa...       Evidence   \n",
       "4  Driving is one of the way how to get around. P...          Claim   \n",
       "\n",
       "  discourse_type_num                                   predictionstring  kfold  \n",
       "0             Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...      1  \n",
       "1         Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59      1  \n",
       "2         Evidence 1    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75      1  \n",
       "3         Evidence 2  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...      1  \n",
       "4            Claim 1  139 140 141 142 143 144 145 146 147 148 149 15...      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_df = pd.read_csv(\"../train_folds.csv\")\n",
    "print(gt_df.shape)\n",
    "gt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0dfbf2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_df = oof_df.drop(\"kfold\", axis=1).merge(gt_df[[\"id\", \"kfold\"]].drop_duplicates(), on=\"id\", how=\"left\")\n",
    "\n",
    "oof_df[\"kfold\"].isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22523772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0033459303983092437,\n",
       " {'Claim': 0.0,\n",
       "  'Concluding Statement': 0.0,\n",
       "  'Counterclaim': 0.0,\n",
       "  'Evidence': 0.010674047795407586,\n",
       "  'Lead': 0.012747464992757121,\n",
       "  'Position': 0.0,\n",
       "  'Rebuttal': 0.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import score_feedback_comp\n",
    "\n",
    "\n",
    "score_feedback_comp(oof_df[oof_df[\"f_7\"] > 0.9999], gt_df, return_class_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2b428b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>f_9</th>\n",
       "      <th>...</th>\n",
       "      <th>f_32</th>\n",
       "      <th>f_33</th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>idx</th>\n",
       "      <th>overlap</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>0.934854</td>\n",
       "      <td>0.934854</td>\n",
       "      <td>0.934854</td>\n",
       "      <td>0.934854</td>\n",
       "      <td>0.934854</td>\n",
       "      <td>0.934854</td>\n",
       "      <td>0.934854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533865</td>\n",
       "      <td>0.741036</td>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23028993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007968</td>\n",
       "      <td>0.835279</td>\n",
       "      <td>0.851875</td>\n",
       "      <td>0.868470</td>\n",
       "      <td>0.885066</td>\n",
       "      <td>0.901662</td>\n",
       "      <td>0.918258</td>\n",
       "      <td>0.934854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533865</td>\n",
       "      <td>0.741036</td>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0 1</td>\n",
       "      <td>23028994</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011952</td>\n",
       "      <td>0.835279</td>\n",
       "      <td>0.841012</td>\n",
       "      <td>0.846746</td>\n",
       "      <td>0.852479</td>\n",
       "      <td>0.879938</td>\n",
       "      <td>0.907396</td>\n",
       "      <td>0.934854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533865</td>\n",
       "      <td>0.741036</td>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0 1 2</td>\n",
       "      <td>23028995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.015936</td>\n",
       "      <td>0.835279</td>\n",
       "      <td>0.843879</td>\n",
       "      <td>0.852479</td>\n",
       "      <td>0.859843</td>\n",
       "      <td>0.867206</td>\n",
       "      <td>0.901030</td>\n",
       "      <td>0.934854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533865</td>\n",
       "      <td>0.741036</td>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0 1 2 3</td>\n",
       "      <td>23028996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.019920</td>\n",
       "      <td>0.835279</td>\n",
       "      <td>0.846746</td>\n",
       "      <td>0.857388</td>\n",
       "      <td>0.867206</td>\n",
       "      <td>0.870778</td>\n",
       "      <td>0.893327</td>\n",
       "      <td>0.934854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533865</td>\n",
       "      <td>0.741036</td>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0 1 2 3 4</td>\n",
       "      <td>23028997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023904</td>\n",
       "      <td>0.835279</td>\n",
       "      <td>0.849613</td>\n",
       "      <td>0.862297</td>\n",
       "      <td>0.867804</td>\n",
       "      <td>0.869789</td>\n",
       "      <td>0.882945</td>\n",
       "      <td>0.934854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533865</td>\n",
       "      <td>0.741036</td>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0 1 2 3 4 5</td>\n",
       "      <td>23028998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027888</td>\n",
       "      <td>0.835279</td>\n",
       "      <td>0.852479</td>\n",
       "      <td>0.863708</td>\n",
       "      <td>0.867206</td>\n",
       "      <td>0.868401</td>\n",
       "      <td>0.872564</td>\n",
       "      <td>0.934854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533865</td>\n",
       "      <td>0.741036</td>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0 1 2 3 4 5 6</td>\n",
       "      <td>23028999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.031873</td>\n",
       "      <td>0.835279</td>\n",
       "      <td>0.854351</td>\n",
       "      <td>0.864874</td>\n",
       "      <td>0.867804</td>\n",
       "      <td>0.870732</td>\n",
       "      <td>0.872453</td>\n",
       "      <td>0.934854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533865</td>\n",
       "      <td>0.741036</td>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0 1 2 3 4 5 6 7</td>\n",
       "      <td>23029000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035857</td>\n",
       "      <td>0.835279</td>\n",
       "      <td>0.856222</td>\n",
       "      <td>0.866040</td>\n",
       "      <td>0.868401</td>\n",
       "      <td>0.871124</td>\n",
       "      <td>0.872342</td>\n",
       "      <td>0.934854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533865</td>\n",
       "      <td>0.741036</td>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8</td>\n",
       "      <td>23029001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039841</td>\n",
       "      <td>0.835279</td>\n",
       "      <td>0.858094</td>\n",
       "      <td>0.867206</td>\n",
       "      <td>0.869229</td>\n",
       "      <td>0.870736</td>\n",
       "      <td>0.872231</td>\n",
       "      <td>0.934854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533865</td>\n",
       "      <td>0.741036</td>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9</td>\n",
       "      <td>23029002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.043825</td>\n",
       "      <td>0.835279</td>\n",
       "      <td>0.859965</td>\n",
       "      <td>0.867089</td>\n",
       "      <td>0.868401</td>\n",
       "      <td>0.870510</td>\n",
       "      <td>0.872120</td>\n",
       "      <td>0.934854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533865</td>\n",
       "      <td>0.741036</td>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10</td>\n",
       "      <td>23029003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047809</td>\n",
       "      <td>0.835279</td>\n",
       "      <td>0.861837</td>\n",
       "      <td>0.867148</td>\n",
       "      <td>0.869229</td>\n",
       "      <td>0.871124</td>\n",
       "      <td>0.872926</td>\n",
       "      <td>0.934854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533865</td>\n",
       "      <td>0.741036</td>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11</td>\n",
       "      <td>23029004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051793</td>\n",
       "      <td>0.835279</td>\n",
       "      <td>0.863708</td>\n",
       "      <td>0.867206</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.871898</td>\n",
       "      <td>0.874736</td>\n",
       "      <td>0.934854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533865</td>\n",
       "      <td>0.741036</td>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12</td>\n",
       "      <td>23029005</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055777</td>\n",
       "      <td>0.835279</td>\n",
       "      <td>0.864262</td>\n",
       "      <td>0.867604</td>\n",
       "      <td>0.870396</td>\n",
       "      <td>0.871900</td>\n",
       "      <td>0.874374</td>\n",
       "      <td>0.934854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533865</td>\n",
       "      <td>0.741036</td>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13</td>\n",
       "      <td>23029006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059761</td>\n",
       "      <td>0.835279</td>\n",
       "      <td>0.864816</td>\n",
       "      <td>0.868003</td>\n",
       "      <td>0.870681</td>\n",
       "      <td>0.871899</td>\n",
       "      <td>0.874012</td>\n",
       "      <td>0.934854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533865</td>\n",
       "      <td>0.741036</td>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14</td>\n",
       "      <td>23029007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063745</td>\n",
       "      <td>0.835279</td>\n",
       "      <td>0.865370</td>\n",
       "      <td>0.868401</td>\n",
       "      <td>0.870708</td>\n",
       "      <td>0.871902</td>\n",
       "      <td>0.875494</td>\n",
       "      <td>0.934854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533865</td>\n",
       "      <td>0.741036</td>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15</td>\n",
       "      <td>23029008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067729</td>\n",
       "      <td>0.707354</td>\n",
       "      <td>0.859965</td>\n",
       "      <td>0.867604</td>\n",
       "      <td>0.870681</td>\n",
       "      <td>0.871900</td>\n",
       "      <td>0.875241</td>\n",
       "      <td>0.934854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533865</td>\n",
       "      <td>0.741036</td>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16</td>\n",
       "      <td>23029009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071713</td>\n",
       "      <td>0.707354</td>\n",
       "      <td>0.849613</td>\n",
       "      <td>0.867148</td>\n",
       "      <td>0.870368</td>\n",
       "      <td>0.871899</td>\n",
       "      <td>0.874989</td>\n",
       "      <td>0.934854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533865</td>\n",
       "      <td>0.741036</td>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17</td>\n",
       "      <td>23029010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075697</td>\n",
       "      <td>0.707354</td>\n",
       "      <td>0.835279</td>\n",
       "      <td>0.867031</td>\n",
       "      <td>0.870056</td>\n",
       "      <td>0.871898</td>\n",
       "      <td>0.874736</td>\n",
       "      <td>0.934854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533865</td>\n",
       "      <td>0.741036</td>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18</td>\n",
       "      <td>23029011</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.079681</td>\n",
       "      <td>0.707354</td>\n",
       "      <td>0.765804</td>\n",
       "      <td>0.864816</td>\n",
       "      <td>0.869229</td>\n",
       "      <td>0.871511</td>\n",
       "      <td>0.874374</td>\n",
       "      <td>0.934854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.533865</td>\n",
       "      <td>0.741036</td>\n",
       "      <td>0000D23A521A</td>\n",
       "      <td>Lead</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19</td>\n",
       "      <td>23029012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     f_0  f_1       f_2       f_3       f_4       f_5       f_6       f_7  \\\n",
       "0    1.0  0.0  0.003984  0.934854  0.934854  0.934854  0.934854  0.934854   \n",
       "1    2.0  0.0  0.007968  0.835279  0.851875  0.868470  0.885066  0.901662   \n",
       "2    3.0  0.0  0.011952  0.835279  0.841012  0.846746  0.852479  0.879938   \n",
       "3    4.0  0.0  0.015936  0.835279  0.843879  0.852479  0.859843  0.867206   \n",
       "4    5.0  0.0  0.019920  0.835279  0.846746  0.857388  0.867206  0.870778   \n",
       "5    6.0  0.0  0.023904  0.835279  0.849613  0.862297  0.867804  0.869789   \n",
       "6    7.0  0.0  0.027888  0.835279  0.852479  0.863708  0.867206  0.868401   \n",
       "7    8.0  0.0  0.031873  0.835279  0.854351  0.864874  0.867804  0.870732   \n",
       "8    9.0  0.0  0.035857  0.835279  0.856222  0.866040  0.868401  0.871124   \n",
       "9   10.0  0.0  0.039841  0.835279  0.858094  0.867206  0.869229  0.870736   \n",
       "10  11.0  0.0  0.043825  0.835279  0.859965  0.867089  0.868401  0.870510   \n",
       "11  12.0  0.0  0.047809  0.835279  0.861837  0.867148  0.869229  0.871124   \n",
       "12  13.0  0.0  0.051793  0.835279  0.863708  0.867206  0.870056  0.871898   \n",
       "13  14.0  0.0  0.055777  0.835279  0.864262  0.867604  0.870396  0.871900   \n",
       "14  15.0  0.0  0.059761  0.835279  0.864816  0.868003  0.870681  0.871899   \n",
       "15  16.0  0.0  0.063745  0.835279  0.865370  0.868401  0.870708  0.871902   \n",
       "16  17.0  0.0  0.067729  0.707354  0.859965  0.867604  0.870681  0.871900   \n",
       "17  18.0  0.0  0.071713  0.707354  0.849613  0.867148  0.870368  0.871899   \n",
       "18  19.0  0.0  0.075697  0.707354  0.835279  0.867031  0.870056  0.871898   \n",
       "19  20.0  0.0  0.079681  0.707354  0.765804  0.864816  0.869229  0.871511   \n",
       "\n",
       "         f_8       f_9  ...      f_32      f_33            id  class  begin  \\\n",
       "0   0.934854  0.934854  ...  0.533865  0.741036  0000D23A521A   Lead      0   \n",
       "1   0.918258  0.934854  ...  0.533865  0.741036  0000D23A521A   Lead      0   \n",
       "2   0.907396  0.934854  ...  0.533865  0.741036  0000D23A521A   Lead      0   \n",
       "3   0.901030  0.934854  ...  0.533865  0.741036  0000D23A521A   Lead      0   \n",
       "4   0.893327  0.934854  ...  0.533865  0.741036  0000D23A521A   Lead      0   \n",
       "5   0.882945  0.934854  ...  0.533865  0.741036  0000D23A521A   Lead      0   \n",
       "6   0.872564  0.934854  ...  0.533865  0.741036  0000D23A521A   Lead      0   \n",
       "7   0.872453  0.934854  ...  0.533865  0.741036  0000D23A521A   Lead      0   \n",
       "8   0.872342  0.934854  ...  0.533865  0.741036  0000D23A521A   Lead      0   \n",
       "9   0.872231  0.934854  ...  0.533865  0.741036  0000D23A521A   Lead      0   \n",
       "10  0.872120  0.934854  ...  0.533865  0.741036  0000D23A521A   Lead      0   \n",
       "11  0.872926  0.934854  ...  0.533865  0.741036  0000D23A521A   Lead      0   \n",
       "12  0.874736  0.934854  ...  0.533865  0.741036  0000D23A521A   Lead      0   \n",
       "13  0.874374  0.934854  ...  0.533865  0.741036  0000D23A521A   Lead      0   \n",
       "14  0.874012  0.934854  ...  0.533865  0.741036  0000D23A521A   Lead      0   \n",
       "15  0.875494  0.934854  ...  0.533865  0.741036  0000D23A521A   Lead      0   \n",
       "16  0.875241  0.934854  ...  0.533865  0.741036  0000D23A521A   Lead      0   \n",
       "17  0.874989  0.934854  ...  0.533865  0.741036  0000D23A521A   Lead      0   \n",
       "18  0.874736  0.934854  ...  0.533865  0.741036  0000D23A521A   Lead      0   \n",
       "19  0.874374  0.934854  ...  0.533865  0.741036  0000D23A521A   Lead      0   \n",
       "\n",
       "    end                                   predictionstring       idx  overlap  \\\n",
       "0     1                                                  0  23028993      0.0   \n",
       "1     2                                                0 1  23028994      0.0   \n",
       "2     3                                              0 1 2  23028995      0.0   \n",
       "3     4                                            0 1 2 3  23028996      0.0   \n",
       "4     5                                          0 1 2 3 4  23028997      0.0   \n",
       "5     6                                        0 1 2 3 4 5  23028998      0.0   \n",
       "6     7                                      0 1 2 3 4 5 6  23028999      0.0   \n",
       "7     8                                    0 1 2 3 4 5 6 7  23029000      0.0   \n",
       "8     9                                  0 1 2 3 4 5 6 7 8  23029001      0.0   \n",
       "9    10                                0 1 2 3 4 5 6 7 8 9  23029002      0.0   \n",
       "10   11                             0 1 2 3 4 5 6 7 8 9 10  23029003      0.0   \n",
       "11   12                          0 1 2 3 4 5 6 7 8 9 10 11  23029004      0.0   \n",
       "12   13                       0 1 2 3 4 5 6 7 8 9 10 11 12  23029005      0.0   \n",
       "13   14                    0 1 2 3 4 5 6 7 8 9 10 11 12 13  23029006      0.0   \n",
       "14   15                 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14  23029007      0.0   \n",
       "15   16              0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  23029008      0.0   \n",
       "16   17           0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  23029009      0.0   \n",
       "17   18        0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  23029010      0.0   \n",
       "18   19     0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  23029011      0.0   \n",
       "19   20  0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  23029012      0.0   \n",
       "\n",
       "    kfold  \n",
       "0       3  \n",
       "1       3  \n",
       "2       3  \n",
       "3       3  \n",
       "4       3  \n",
       "5       3  \n",
       "6       3  \n",
       "7       3  \n",
       "8       3  \n",
       "9       3  \n",
       "10      3  \n",
       "11      3  \n",
       "12      3  \n",
       "13      3  \n",
       "14      3  \n",
       "15      3  \n",
       "16      3  \n",
       "17      3  \n",
       "18      3  \n",
       "19      3  \n",
       "\n",
       "[20 rows x 42 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_df[\"begin\"] = oof_df[\"predictionstring\"].apply(lambda x: int(str(x).split()[0]))\n",
    "#oof_df[\"end\"] = oof_df[\"predictionstring\"].apply(lambda x: int(str(x).split()[-1]))\n",
    "#oof_df[\"len\"] = oof_df[\"end\"] - oof_df[\"begin\"] + 1\n",
    "#oof_df[\"loc\"] = (oof_df[\"begin\"] + oof_df[\"end\"]) / 2\n",
    "\n",
    "oof_df = oof_df.sort_values([\"id\", \"begin\"]).reset_index(drop=True)\n",
    "oof_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d909ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35639825352811244"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oof_df[\"target\"] = oof_df[\"overlap\"] >= 0.5\n",
    "oof_df[\"target\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c2a3e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "discourse_types = gt_df[\"discourse_type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcbd99fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def read_texts(directory):\n",
    "    names, texts = [], []\n",
    "    for f in tqdm(list(os.listdir(directory))):\n",
    "        names.append(f.replace('.txt', ''))\n",
    "        texts.append(open(directory + f, 'r').read())\n",
    "    df = pd.DataFrame({'id': names, 'full_text': texts})\n",
    "    return df\n",
    "\n",
    "#text_df = read_texts(\"data/train/\")\n",
    "#print(text_df.shape)\n",
    "#text_df[\"full_text_len\"] = text_df[\"full_text\"].apply(lambda x: len(x.split()))\n",
    "#text_df.head()\n",
    "\n",
    "#oof_df = oof_df.merge(text_df, on=\"id\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a0920ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dict = {'Lead': [f\"f_{i}\" for i in range(34)],\n",
    " 'Position': [f\"f_{i}\" for i in range(34)],\n",
    " 'Evidence': [f\"f_{i}\" for i in range(20)],\n",
    " 'Claim': [f\"f_{i}\" for i in range(20)],\n",
    " 'Concluding Statement': [f\"f_{i}\" for i in range(34)],\n",
    " 'Counterclaim': [f\"f_{i}\" for i in range(17)] + [f\"f_{i}\" for i in range(27, 34)],\n",
    " 'Rebuttal': [f\"f_{i}\" for i in range(17)]}\n",
    "\n",
    "\n",
    "target = \"target\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8288617d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory â€˜gbm_modelsâ€™: File exists\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead 34\n",
      "[0]\tval-auc:0.92984\n",
      "[200]\tval-auc:0.96178\n",
      "[400]\tval-auc:0.96282\n",
      "[507]\tval-auc:0.96290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/exx/.conda/envs/torch/lib/python3.8/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 528393, number of negative: 1071022\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020848 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8443\n",
      "[LightGBM] [Info] Number of data points in the train set: 1599415, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.330366 -> initscore=-0.706528\n",
      "[LightGBM] [Info] Start training from score -0.706528\n",
      "[200]\tvalid_0's auc: 0.962575\n",
      "[400]\tvalid_0's auc: 0.963113\n",
      "[600]\tvalid_0's auc: 0.962662\n",
      "...\n",
      "[0]\tval-auc:0.93488\n",
      "[200]\tval-auc:0.96381\n",
      "[400]\tval-auc:0.96472\n",
      "[473]\tval-auc:0.96469\n",
      "[LightGBM] [Info] Number of positive: 531235, number of negative: 1076718\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021249 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8453\n",
      "[LightGBM] [Info] Number of data points in the train set: 1607953, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.330380 -> initscore=-0.706468\n",
      "[LightGBM] [Info] Start training from score -0.706468\n",
      "[200]\tvalid_0's auc: 0.96435\n",
      "[400]\tvalid_0's auc: 0.964704\n",
      "...\n",
      "[0]\tval-auc:0.93195\n",
      "[200]\tval-auc:0.96318\n",
      "[400]\tval-auc:0.96399\n",
      "[600]\tval-auc:0.96423\n",
      "[652]\tval-auc:0.96419\n",
      "[LightGBM] [Info] Number of positive: 526021, number of negative: 1075046\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.019477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8443\n",
      "[LightGBM] [Info] Number of data points in the train set: 1601067, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.328544 -> initscore=-0.714778\n",
      "[LightGBM] [Info] Start training from score -0.714778\n",
      "[200]\tvalid_0's auc: 0.96391\n",
      "[400]\tvalid_0's auc: 0.964264\n",
      "[600]\tvalid_0's auc: 0.964275\n",
      "[800]\tvalid_0's auc: 0.964043\n",
      "...\n",
      "[0]\tval-auc:0.93183\n",
      "[200]\tval-auc:0.96164\n",
      "[400]\tval-auc:0.96255\n",
      "[550]\tval-auc:0.96258\n",
      "[LightGBM] [Info] Number of positive: 526688, number of negative: 1076545\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020826 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8443\n",
      "[LightGBM] [Info] Number of data points in the train set: 1603233, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.328516 -> initscore=-0.714904\n",
      "[LightGBM] [Info] Start training from score -0.714904\n",
      "[200]\tvalid_0's auc: 0.962413\n",
      "[400]\tvalid_0's auc: 0.9627\n",
      "[600]\tvalid_0's auc: 0.962615\n",
      "...\n",
      "[0]\tval-auc:0.93006\n",
      "[200]\tval-auc:0.95947\n",
      "[301]\tval-auc:0.95982\n",
      "[LightGBM] [Info] Number of positive: 529939, number of negative: 1078797\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.021551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8447\n",
      "[LightGBM] [Info] Number of data points in the train set: 1608736, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.329413 -> initscore=-0.710840\n",
      "[LightGBM] [Info] Start training from score -0.710840\n",
      "[200]\tvalid_0's auc: 0.960392\n",
      "...\n",
      "removing overlaps...\n",
      "tuning...\n",
      "(12082, 5) 9305\n",
      "\n",
      "0.6 0.8751799520127966\n",
      "\n",
      "Position 34\n",
      "[0]\tval-auc:0.88959\n",
      "[200]\tval-auc:0.91210\n",
      "[400]\tval-auc:0.91309\n",
      "[414]\tval-auc:0.91307\n",
      "[LightGBM] [Info] Number of positive: 274973, number of negative: 593129\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8464\n",
      "[LightGBM] [Info] Number of data points in the train set: 868102, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.316752 -> initscore=-0.768739\n",
      "[LightGBM] [Info] Start training from score -0.768739\n",
      "[200]\tvalid_0's auc: 0.91241\n",
      "[400]\tvalid_0's auc: 0.913241\n",
      "...\n",
      "[0]\tval-auc:0.89168\n",
      "[200]\tval-auc:0.91324\n",
      "[400]\tval-auc:0.91381\n",
      "[518]\tval-auc:0.91373\n",
      "[LightGBM] [Info] Number of positive: 274537, number of negative: 590393\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004591 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8466\n",
      "[LightGBM] [Info] Number of data points in the train set: 864930, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.317410 -> initscore=-0.765702\n",
      "[LightGBM] [Info] Start training from score -0.765702\n",
      "[200]\tvalid_0's auc: 0.913597\n",
      "[400]\tvalid_0's auc: 0.914507\n",
      "[600]\tvalid_0's auc: 0.914906\n",
      "...\n",
      "[0]\tval-auc:0.89177\n",
      "[200]\tval-auc:0.91493\n",
      "[400]\tval-auc:0.91554\n",
      "[431]\tval-auc:0.91555\n",
      "[LightGBM] [Info] Number of positive: 274962, number of negative: 593431\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004563 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8463\n",
      "[LightGBM] [Info] Number of data points in the train set: 868393, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.316633 -> initscore=-0.769288\n",
      "[LightGBM] [Info] Start training from score -0.769288\n",
      "[200]\tvalid_0's auc: 0.915626\n",
      "[400]\tvalid_0's auc: 0.916449\n",
      "...\n",
      "[0]\tval-auc:0.89794\n",
      "[200]\tval-auc:0.91860\n",
      "[400]\tval-auc:0.91880\n",
      "[423]\tval-auc:0.91879\n",
      "[LightGBM] [Info] Number of positive: 274602, number of negative: 595914\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8464\n",
      "[LightGBM] [Info] Number of data points in the train set: 870516, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.315447 -> initscore=-0.774774\n",
      "[LightGBM] [Info] Start training from score -0.774774\n",
      "[200]\tvalid_0's auc: 0.918951\n",
      "[400]\tvalid_0's auc: 0.919717\n",
      "...\n",
      "[0]\tval-auc:0.88982\n",
      "[200]\tval-auc:0.91213\n",
      "[400]\tval-auc:0.91321\n",
      "[535]\tval-auc:0.91342\n",
      "[LightGBM] [Info] Number of positive: 275266, number of negative: 591373\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8465\n",
      "[LightGBM] [Info] Number of data points in the train set: 866639, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.317625 -> initscore=-0.764709\n",
      "[LightGBM] [Info] Start training from score -0.764709\n",
      "[200]\tvalid_0's auc: 0.912243\n",
      "[400]\tvalid_0's auc: 0.913252\n",
      "[600]\tvalid_0's auc: 0.913396\n",
      "...\n",
      "removing overlaps...\n",
      "tuning...\n",
      "(17979, 5) 15419\n",
      "\n",
      "0.52 0.7652997054248172\n",
      "\n",
      "Evidence 20\n",
      "[0]\tval-auc:0.76371\n",
      "[200]\tval-auc:0.84531\n",
      "[400]\tval-auc:0.85060\n",
      "[600]\tval-auc:0.85307\n",
      "[800]\tval-auc:0.85486\n",
      "[1000]\tval-auc:0.85622\n",
      "[1200]\tval-auc:0.85703\n",
      "[1400]\tval-auc:0.85759\n",
      "[1600]\tval-auc:0.85800\n",
      "[1800]\tval-auc:0.85831\n",
      "[1999]\tval-auc:0.85850\n",
      "[LightGBM] [Info] Number of positive: 6573550, number of negative: 9704346\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5099\n",
      "[LightGBM] [Info] Number of data points in the train set: 16277896, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.403833 -> initscore=-0.389520\n",
      "[LightGBM] [Info] Start training from score -0.389520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's auc: 0.848422\n",
      "[400]\tvalid_0's auc: 0.85333\n",
      "[600]\tvalid_0's auc: 0.8551\n",
      "[800]\tvalid_0's auc: 0.855887\n",
      "[1000]\tvalid_0's auc: 0.856745\n",
      "[1200]\tvalid_0's auc: 0.857343\n",
      "[1400]\tvalid_0's auc: 0.857788\n",
      "[1600]\tvalid_0's auc: 0.85808\n",
      "[1800]\tvalid_0's auc: 0.858293\n",
      "[2000]\tvalid_0's auc: 0.858524\n",
      "[2200]\tvalid_0's auc: 0.858575\n",
      "[2400]\tvalid_0's auc: 0.858702\n",
      "[2600]\tvalid_0's auc: 0.858911\n",
      "...\n",
      "[0]\tval-auc:0.77156\n",
      "[200]\tval-auc:0.85047\n",
      "[400]\tval-auc:0.85575\n",
      "[600]\tval-auc:0.85819\n",
      "[800]\tval-auc:0.86009\n",
      "[1000]\tval-auc:0.86134\n",
      "[1200]\tval-auc:0.86218\n",
      "[1400]\tval-auc:0.86274\n",
      "[1600]\tval-auc:0.86330\n",
      "[1800]\tval-auc:0.86368\n",
      "[1999]\tval-auc:0.86381\n",
      "[LightGBM] [Info] Number of positive: 6610971, number of negative: 9771960\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5099\n",
      "[LightGBM] [Info] Number of data points in the train set: 16382931, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.403528 -> initscore=-0.390787\n",
      "[LightGBM] [Info] Start training from score -0.390787\n",
      "[200]\tvalid_0's auc: 0.853518\n",
      "[400]\tvalid_0's auc: 0.858434\n",
      "[600]\tvalid_0's auc: 0.860297\n",
      "[800]\tvalid_0's auc: 0.861399\n",
      "[1000]\tvalid_0's auc: 0.862215\n",
      "[1200]\tvalid_0's auc: 0.862908\n",
      "[1400]\tvalid_0's auc: 0.863404\n",
      "[1600]\tvalid_0's auc: 0.863802\n",
      "[1800]\tvalid_0's auc: 0.864053\n",
      "[2000]\tvalid_0's auc: 0.864271\n",
      "[2200]\tvalid_0's auc: 0.864388\n",
      "[2400]\tvalid_0's auc: 0.864497\n",
      "[2600]\tvalid_0's auc: 0.864571\n",
      "...\n",
      "[0]\tval-auc:0.76104\n",
      "[200]\tval-auc:0.85027\n",
      "[400]\tval-auc:0.85524\n",
      "[600]\tval-auc:0.85743\n",
      "[800]\tval-auc:0.85936\n",
      "[1000]\tval-auc:0.86089\n",
      "[1200]\tval-auc:0.86186\n",
      "[1400]\tval-auc:0.86253\n",
      "[1600]\tval-auc:0.86295\n",
      "[1800]\tval-auc:0.86328\n",
      "[1999]\tval-auc:0.86357\n",
      "[LightGBM] [Info] Number of positive: 6612730, number of negative: 9727928\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.059317 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5099\n",
      "[LightGBM] [Info] Number of data points in the train set: 16340658, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.404680 -> initscore=-0.386004\n",
      "[LightGBM] [Info] Start training from score -0.386004\n",
      "[200]\tvalid_0's auc: 0.853475\n",
      "[400]\tvalid_0's auc: 0.857762\n",
      "[600]\tvalid_0's auc: 0.859611\n",
      "[800]\tvalid_0's auc: 0.860859\n",
      "[1000]\tvalid_0's auc: 0.861671\n",
      "[1200]\tvalid_0's auc: 0.862354\n",
      "[1400]\tvalid_0's auc: 0.862716\n",
      "[1600]\tvalid_0's auc: 0.863076\n",
      "[1800]\tvalid_0's auc: 0.863359\n",
      "[2000]\tvalid_0's auc: 0.863634\n",
      "[2200]\tvalid_0's auc: 0.863859\n",
      "[2400]\tvalid_0's auc: 0.864033\n",
      "[2600]\tvalid_0's auc: 0.864107\n",
      "...\n",
      "[0]\tval-auc:0.76795\n",
      "[200]\tval-auc:0.84986\n",
      "[400]\tval-auc:0.85512\n",
      "[600]\tval-auc:0.85766\n",
      "[800]\tval-auc:0.85963\n",
      "[1000]\tval-auc:0.86116\n",
      "[1200]\tval-auc:0.86201\n",
      "[1400]\tval-auc:0.86269\n",
      "[1600]\tval-auc:0.86312\n",
      "[1800]\tval-auc:0.86342\n",
      "[1999]\tval-auc:0.86379\n",
      "[LightGBM] [Info] Number of positive: 6596141, number of negative: 9673276\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057562 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5098\n",
      "[LightGBM] [Info] Number of data points in the train set: 16269417, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.405432 -> initscore=-0.382882\n",
      "[LightGBM] [Info] Start training from score -0.382882\n",
      "[200]\tvalid_0's auc: 0.853127\n",
      "[400]\tvalid_0's auc: 0.858142\n",
      "[600]\tvalid_0's auc: 0.860368\n",
      "[800]\tvalid_0's auc: 0.861563\n",
      "[1000]\tvalid_0's auc: 0.862131\n",
      "[1200]\tvalid_0's auc: 0.862779\n",
      "[1400]\tvalid_0's auc: 0.86319\n",
      "[1600]\tvalid_0's auc: 0.863647\n",
      "[1800]\tvalid_0's auc: 0.863847\n",
      "[2000]\tvalid_0's auc: 0.864095\n",
      "[2200]\tvalid_0's auc: 0.864247\n",
      "[2400]\tvalid_0's auc: 0.864355\n",
      "[2600]\tvalid_0's auc: 0.864518\n",
      "...\n",
      "[0]\tval-auc:0.76281\n",
      "[200]\tval-auc:0.84363\n",
      "[400]\tval-auc:0.84899\n",
      "[600]\tval-auc:0.85151\n",
      "[800]\tval-auc:0.85323\n",
      "[1000]\tval-auc:0.85438\n",
      "[1200]\tval-auc:0.85530\n",
      "[1400]\tval-auc:0.85580\n",
      "[1600]\tval-auc:0.85612\n",
      "[1800]\tval-auc:0.85638\n",
      "[1999]\tval-auc:0.85657\n",
      "[LightGBM] [Info] Number of positive: 6607536, number of negative: 9717678\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.057319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5099\n",
      "[LightGBM] [Info] Number of data points in the train set: 16325214, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.404744 -> initscore=-0.385736\n",
      "[LightGBM] [Info] Start training from score -0.385736\n",
      "[200]\tvalid_0's auc: 0.84681\n",
      "[400]\tvalid_0's auc: 0.851559\n",
      "[600]\tvalid_0's auc: 0.85346\n",
      "[800]\tvalid_0's auc: 0.854506\n",
      "[1000]\tvalid_0's auc: 0.855203\n",
      "[1200]\tvalid_0's auc: 0.855765\n",
      "[1400]\tvalid_0's auc: 0.856221\n",
      "[1600]\tvalid_0's auc: 0.856466\n",
      "[1800]\tvalid_0's auc: 0.856837\n",
      "[2000]\tvalid_0's auc: 0.857037\n",
      "[2200]\tvalid_0's auc: 0.857194\n",
      "[2400]\tvalid_0's auc: 0.857264\n",
      "[2600]\tvalid_0's auc: 0.857348\n",
      "...\n",
      "removing overlaps...\n",
      "tuning...\n",
      "(59465, 5) 45702\n",
      "\n",
      "0.55 0.7806758953090848\n",
      "\n",
      "Claim 20\n",
      "[0]\tval-auc:0.78300\n",
      "[200]\tval-auc:0.84761\n",
      "[400]\tval-auc:0.85233\n",
      "[600]\tval-auc:0.85422\n",
      "[800]\tval-auc:0.85538\n",
      "[1000]\tval-auc:0.85623\n",
      "[1200]\tval-auc:0.85670\n",
      "[1400]\tval-auc:0.85713\n",
      "[1600]\tval-auc:0.85735\n",
      "[1713]\tval-auc:0.85733\n",
      "[LightGBM] [Info] Number of positive: 889756, number of negative: 1868121\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4889\n",
      "[LightGBM] [Info] Number of data points in the train set: 2757877, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.322624 -> initscore=-0.741741\n",
      "[LightGBM] [Info] Start training from score -0.741741\n",
      "[200]\tvalid_0's auc: 0.849418\n",
      "[400]\tvalid_0's auc: 0.853981\n",
      "[600]\tvalid_0's auc: 0.855706\n",
      "[800]\tvalid_0's auc: 0.85691\n",
      "[1000]\tvalid_0's auc: 0.85738\n",
      "[1200]\tvalid_0's auc: 0.857925\n",
      "[1400]\tvalid_0's auc: 0.858535\n",
      "[1600]\tvalid_0's auc: 0.858795\n",
      "[1800]\tvalid_0's auc: 0.859141\n",
      "[2000]\tvalid_0's auc: 0.859446\n",
      "[2200]\tvalid_0's auc: 0.85949\n",
      "...\n",
      "[0]\tval-auc:0.78636\n",
      "[200]\tval-auc:0.85143\n",
      "[400]\tval-auc:0.85579\n",
      "[600]\tval-auc:0.85763\n",
      "[800]\tval-auc:0.85850\n",
      "[1000]\tval-auc:0.85922\n",
      "[1200]\tval-auc:0.85959\n",
      "[1342]\tval-auc:0.85970\n",
      "[LightGBM] [Info] Number of positive: 891925, number of negative: 1866907\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4889\n",
      "[LightGBM] [Info] Number of data points in the train set: 2758832, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.323298 -> initscore=-0.738656\n",
      "[LightGBM] [Info] Start training from score -0.738656\n",
      "[200]\tvalid_0's auc: 0.852646\n",
      "[400]\tvalid_0's auc: 0.857374\n",
      "[600]\tvalid_0's auc: 0.859174\n",
      "[800]\tvalid_0's auc: 0.860217\n",
      "[1000]\tvalid_0's auc: 0.860956\n",
      "[1200]\tvalid_0's auc: 0.861584\n",
      "[1400]\tvalid_0's auc: 0.861947\n",
      "[1600]\tvalid_0's auc: 0.862134\n",
      "[1800]\tvalid_0's auc: 0.862637\n",
      "...\n",
      "[0]\tval-auc:0.78753\n",
      "[200]\tval-auc:0.85174\n",
      "[400]\tval-auc:0.85646\n",
      "[600]\tval-auc:0.85831\n",
      "[800]\tval-auc:0.85943\n",
      "[1000]\tval-auc:0.86000\n",
      "[1200]\tval-auc:0.86044\n",
      "[1230]\tval-auc:0.86046\n",
      "[LightGBM] [Info] Number of positive: 887566, number of negative: 1859303\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4891\n",
      "[LightGBM] [Info] Number of data points in the train set: 2746869, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.323119 -> initscore=-0.739474\n",
      "[LightGBM] [Info] Start training from score -0.739474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's auc: 0.853034\n",
      "[400]\tvalid_0's auc: 0.857495\n",
      "[600]\tvalid_0's auc: 0.859171\n",
      "[800]\tvalid_0's auc: 0.860375\n",
      "[1000]\tvalid_0's auc: 0.860983\n",
      "[1200]\tvalid_0's auc: 0.861091\n",
      "[1400]\tvalid_0's auc: 0.861514\n",
      "[1600]\tvalid_0's auc: 0.861757\n",
      "...\n",
      "[0]\tval-auc:0.78869\n",
      "[200]\tval-auc:0.85313\n",
      "[400]\tval-auc:0.85750\n",
      "[600]\tval-auc:0.85906\n",
      "[800]\tval-auc:0.86005\n",
      "[1000]\tval-auc:0.86061\n",
      "[1200]\tval-auc:0.86096\n",
      "[1400]\tval-auc:0.86122\n",
      "[1525]\tval-auc:0.86129\n",
      "[LightGBM] [Info] Number of positive: 891769, number of negative: 1868511\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4887\n",
      "[LightGBM] [Info] Number of data points in the train set: 2760280, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.323072 -> initscore=-0.739690\n",
      "[LightGBM] [Info] Start training from score -0.739690\n",
      "[200]\tvalid_0's auc: 0.854627\n",
      "[400]\tvalid_0's auc: 0.858951\n",
      "[600]\tvalid_0's auc: 0.860905\n",
      "[800]\tvalid_0's auc: 0.861938\n",
      "[1000]\tvalid_0's auc: 0.862561\n",
      "[1200]\tvalid_0's auc: 0.863083\n",
      "[1400]\tvalid_0's auc: 0.863567\n",
      "[1600]\tvalid_0's auc: 0.863885\n",
      "[1800]\tvalid_0's auc: 0.863986\n",
      "[2000]\tvalid_0's auc: 0.864116\n",
      "...\n",
      "[0]\tval-auc:0.79348\n",
      "[200]\tval-auc:0.85592\n",
      "[400]\tval-auc:0.85988\n",
      "[600]\tval-auc:0.86170\n",
      "[800]\tval-auc:0.86276\n",
      "[1000]\tval-auc:0.86335\n",
      "[1200]\tval-auc:0.86372\n",
      "[1276]\tval-auc:0.86376\n",
      "[LightGBM] [Info] Number of positive: 894108, number of negative: 1867182\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010414 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4888\n",
      "[LightGBM] [Info] Number of data points in the train set: 2761290, number of used features: 20\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.323801 -> initscore=-0.736359\n",
      "[LightGBM] [Info] Start training from score -0.736359\n",
      "[200]\tvalid_0's auc: 0.856974\n",
      "[400]\tvalid_0's auc: 0.861321\n",
      "[600]\tvalid_0's auc: 0.863103\n",
      "[800]\tvalid_0's auc: 0.864051\n",
      "[1000]\tvalid_0's auc: 0.864801\n",
      "[1200]\tvalid_0's auc: 0.865177\n",
      "[1400]\tvalid_0's auc: 0.865518\n",
      "[1600]\tvalid_0's auc: 0.865827\n",
      "...\n",
      "removing overlaps...\n",
      "tuning...\n",
      "(60919, 5) 50208\n",
      "\n",
      "0.55 0.6896754982367349\n",
      "\n",
      "Concluding Statement 34\n",
      "[0]\tval-auc:0.91413\n",
      "[200]\tval-auc:0.95826\n",
      "[400]\tval-auc:0.96066\n",
      "[600]\tval-auc:0.96149\n",
      "[727]\tval-auc:0.96153\n",
      "[LightGBM] [Info] Number of positive: 428113, number of negative: 583461\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8607\n",
      "[LightGBM] [Info] Number of data points in the train set: 1011574, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.423215 -> initscore=-0.309590\n",
      "[LightGBM] [Info] Start training from score -0.309590\n",
      "[200]\tvalid_0's auc: 0.960885\n",
      "[400]\tvalid_0's auc: 0.962634\n",
      "[600]\tvalid_0's auc: 0.962956\n",
      "[800]\tvalid_0's auc: 0.963261\n",
      "...\n",
      "[0]\tval-auc:0.92025\n",
      "[200]\tval-auc:0.96184\n",
      "[400]\tval-auc:0.96410\n",
      "[600]\tval-auc:0.96491\n",
      "[800]\tval-auc:0.96539\n",
      "[941]\tval-auc:0.96552\n",
      "[LightGBM] [Info] Number of positive: 428088, number of negative: 586185\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005287 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8607\n",
      "[LightGBM] [Info] Number of data points in the train set: 1014273, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.422064 -> initscore=-0.314307\n",
      "[LightGBM] [Info] Start training from score -0.314307\n",
      "[200]\tvalid_0's auc: 0.965071\n",
      "[400]\tvalid_0's auc: 0.966663\n",
      "[600]\tvalid_0's auc: 0.967092\n",
      "[800]\tvalid_0's auc: 0.966979\n",
      "[1000]\tvalid_0's auc: 0.967341\n",
      "[1200]\tvalid_0's auc: 0.96748\n",
      "...\n",
      "[0]\tval-auc:0.91706\n",
      "[200]\tval-auc:0.95862\n",
      "[400]\tval-auc:0.96101\n",
      "[600]\tval-auc:0.96188\n",
      "[631]\tval-auc:0.96186\n",
      "[LightGBM] [Info] Number of positive: 427342, number of negative: 593310\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005819 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8607\n",
      "[LightGBM] [Info] Number of data points in the train set: 1020652, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.418695 -> initscore=-0.328132\n",
      "[LightGBM] [Info] Start training from score -0.328132\n",
      "[200]\tvalid_0's auc: 0.961292\n",
      "[400]\tvalid_0's auc: 0.962779\n",
      "[600]\tvalid_0's auc: 0.963345\n",
      "[800]\tvalid_0's auc: 0.963745\n",
      "...\n",
      "[0]\tval-auc:0.91750\n",
      "[200]\tval-auc:0.95771\n",
      "[400]\tval-auc:0.96010\n",
      "[600]\tval-auc:0.96085\n",
      "[800]\tval-auc:0.96133\n",
      "[858]\tval-auc:0.96134\n",
      "[LightGBM] [Info] Number of positive: 426634, number of negative: 584526\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005158 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8607\n",
      "[LightGBM] [Info] Number of data points in the train set: 1011160, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.421925 -> initscore=-0.314875\n",
      "[LightGBM] [Info] Start training from score -0.314875\n",
      "[200]\tvalid_0's auc: 0.961211\n",
      "[400]\tvalid_0's auc: 0.962909\n",
      "[600]\tvalid_0's auc: 0.963123\n",
      "[800]\tvalid_0's auc: 0.963382\n",
      "[1000]\tvalid_0's auc: 0.963434\n",
      "...\n",
      "[0]\tval-auc:0.92227\n",
      "[200]\tval-auc:0.96198\n",
      "[400]\tval-auc:0.96406\n",
      "[600]\tval-auc:0.96498\n",
      "[800]\tval-auc:0.96531\n",
      "[1000]\tval-auc:0.96553\n",
      "[1141]\tval-auc:0.96562\n",
      "[LightGBM] [Info] Number of positive: 429931, number of negative: 587306\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005275 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8607\n",
      "[LightGBM] [Info] Number of data points in the train set: 1017237, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.422646 -> initscore=-0.311921\n",
      "[LightGBM] [Info] Start training from score -0.311921\n",
      "[200]\tvalid_0's auc: 0.96475\n",
      "[400]\tvalid_0's auc: 0.96691\n",
      "[600]\tvalid_0's auc: 0.967214\n",
      "[800]\tvalid_0's auc: 0.967334\n",
      "[1000]\tvalid_0's auc: 0.967675\n",
      "[1200]\tvalid_0's auc: 0.968002\n",
      "[1400]\tvalid_0's auc: 0.968018\n",
      "...\n",
      "removing overlaps...\n",
      "tuning...\n",
      "(16392, 5) 13505\n",
      "\n",
      "0.52 0.8788101899572964\n",
      "\n",
      "Counterclaim 24\n",
      "[0]\tval-auc:0.88564\n",
      "[200]\tval-auc:0.89987\n",
      "[213]\tval-auc:0.90009\n",
      "[LightGBM] [Info] Number of positive: 163476, number of negative: 856017\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019531 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5961\n",
      "[LightGBM] [Info] Number of data points in the train set: 1019493, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160350 -> initscore=-1.655624\n",
      "[LightGBM] [Info] Start training from score -1.655624\n",
      "[200]\tvalid_0's auc: 0.899368\n",
      "...\n",
      "[0]\tval-auc:0.87815\n",
      "[200]\tval-auc:0.89655\n",
      "[201]\tval-auc:0.89656\n",
      "[LightGBM] [Info] Number of positive: 158124, number of negative: 851068\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004431 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5961\n",
      "[LightGBM] [Info] Number of data points in the train set: 1009192, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.156684 -> initscore=-1.683112\n",
      "[LightGBM] [Info] Start training from score -1.683112\n",
      "[200]\tvalid_0's auc: 0.896516\n",
      "...\n",
      "[0]\tval-auc:0.87363\n",
      "[200]\tval-auc:0.89321\n",
      "[214]\tval-auc:0.89338\n",
      "[LightGBM] [Info] Number of positive: 161170, number of negative: 845477\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5961\n",
      "[LightGBM] [Info] Number of data points in the train set: 1006647, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.160106 -> initscore=-1.657441\n",
      "[LightGBM] [Info] Start training from score -1.657441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\tvalid_0's auc: 0.893421\n",
      "...\n",
      "[0]\tval-auc:0.88835\n",
      "[200]\tval-auc:0.90514\n",
      "[204]\tval-auc:0.90519\n",
      "[LightGBM] [Info] Number of positive: 160755, number of negative: 851183\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004632 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5961\n",
      "[LightGBM] [Info] Number of data points in the train set: 1011938, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.158859 -> initscore=-1.666746\n",
      "[LightGBM] [Info] Start training from score -1.666746\n",
      "[200]\tvalid_0's auc: 0.904364\n",
      "...\n",
      "[0]\tval-auc:0.88757\n",
      "[181]\tval-auc:0.90575\n",
      "[LightGBM] [Info] Number of positive: 161159, number of negative: 867131\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5961\n",
      "[LightGBM] [Info] Number of data points in the train set: 1028290, number of used features: 24\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.156725 -> initscore=-1.682799\n",
      "[LightGBM] [Info] Start training from score -1.682799\n",
      "...\n",
      "removing overlaps...\n",
      "tuning...\n",
      "(14012, 5) 5817\n",
      "\n",
      "0.69 0.603442280945758\n",
      "\n",
      "Rebuttal 17\n",
      "[0]\tval-auc:0.84431\n",
      "[200]\tval-auc:0.86255\n",
      "[253]\tval-auc:0.86190\n",
      "[LightGBM] [Info] Number of positive: 241359, number of negative: 1762014\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007522 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4197\n",
      "[LightGBM] [Info] Number of data points in the train set: 2003373, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.120476 -> initscore=-1.987927\n",
      "[LightGBM] [Info] Start training from score -1.987927\n",
      "[200]\tvalid_0's auc: 0.860841\n",
      "...\n",
      "[0]\tval-auc:0.86691\n",
      "[198]\tval-auc:0.88440\n",
      "[LightGBM] [Info] Number of positive: 237764, number of negative: 1785123\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009377 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4197\n",
      "[LightGBM] [Info] Number of data points in the train set: 2022887, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117537 -> initscore=-2.015964\n",
      "[LightGBM] [Info] Start training from score -2.015964\n",
      "[200]\tvalid_0's auc: 0.883964\n",
      "...\n",
      "[0]\tval-auc:0.86146\n",
      "[200]\tval-auc:0.88211\n",
      "[201]\tval-auc:0.88213\n",
      "[LightGBM] [Info] Number of positive: 237922, number of negative: 1774380\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4197\n",
      "[LightGBM] [Info] Number of data points in the train set: 2012302, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.118234 -> initscore=-2.009263\n",
      "[LightGBM] [Info] Start training from score -2.009263\n",
      "[200]\tvalid_0's auc: 0.881377\n",
      "...\n",
      "[0]\tval-auc:0.84764\n",
      "[200]\tval-auc:0.86418\n",
      "[316]\tval-auc:0.86443\n",
      "[LightGBM] [Info] Number of positive: 237077, number of negative: 1776807\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007118 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4197\n",
      "[LightGBM] [Info] Number of data points in the train set: 2013884, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.117721 -> initscore=-2.014188\n",
      "[LightGBM] [Info] Start training from score -2.014188\n",
      "[200]\tvalid_0's auc: 0.863029\n",
      "...\n",
      "[0]\tval-auc:0.86624\n",
      "[200]\tval-auc:0.88521\n",
      "[243]\tval-auc:0.88505\n",
      "[LightGBM] [Info] Number of positive: 237354, number of negative: 1791324\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007415 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4197\n",
      "[LightGBM] [Info] Number of data points in the train set: 2028678, number of used features: 17\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.116999 -> initscore=-2.021158\n",
      "[LightGBM] [Info] Start training from score -2.021158\n",
      "[200]\tvalid_0's auc: 0.885423\n",
      "...\n",
      "removing overlaps...\n",
      "tuning...\n",
      "(18555, 5) 4337\n",
      "\n",
      "0.71 0.5338662633682618\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "import os\n",
    "\n",
    "os.system('mkdir gbm_models')\n",
    "\n",
    "lgb_param = {\"objective\": \"binary\",\n",
    "             \"metric\": 'auc',\n",
    "             \"boosting\": \"dart\",\n",
    "             \"learning_rate\": 0.1,\n",
    "             \"is_unbalance\": True,\n",
    "                    \"min_data_in_leaf\": 200,\n",
    "                    \"num_leaves\": 15,\n",
    "                    \"feature_fraction\": 0.8,\n",
    "             \"subsample\": 0.5,\n",
    "             \"subsample_freq\": 1\n",
    "                    }\n",
    "\n",
    "\n",
    "xgb_param = {'objective': 'reg:logistic',\n",
    "         'eval_metric': \"auc\",\n",
    "         'learning_rate': 0.05,\n",
    "         'max_depth': 4,\n",
    "         \"min_child_weight\": 200,\n",
    "         \"colsample_bynode\": 0.8,\n",
    "         \"subsample\": 0.5,\n",
    "         \"tree_method\": 'gpu_hist', \"gpu_id\": 0\n",
    "    }\n",
    "\n",
    "y_oof = np.zeros(oof_df.shape[0])\n",
    "res = dict()\n",
    "best_th = dict()\n",
    "\n",
    "lvl1_stacking_df = []\n",
    "\n",
    "for dtype in discourse_types:\n",
    "    if dtype == \"Evidence\":\n",
    "        lgb_param[\"boosting\"] = \"gbdt\"\n",
    "        lgb_param[\"learning_rate\"] = 0.05\n",
    "    else:\n",
    "        lgb_param[\"boosting\"] = \"dart\"\n",
    "        lgb_param[\"learning_rate\"] = 0.1\n",
    "        \n",
    "        \n",
    "    features = features_dict[dtype]\n",
    "\n",
    "    \n",
    "    all_indices = np.where(oof_df[\"class\"] == dtype)[0]\n",
    "    discourse_df = oof_df[oof_df[\"class\"] == dtype].reset_index(drop=True)\n",
    "    \n",
    "    tm = discourse_df[\"target\"].mean()\n",
    "    \n",
    "    xgb_param[\"scale_pos_weight\"] = (1 - tm)/tm\n",
    "    \n",
    "    best_its = []\n",
    "    \n",
    "    print(dtype, len(features))\n",
    "    for f in range(N_FOLDS):\n",
    "        val_ind = all_indices[np.where(discourse_df[\"kfold\"] == f)[0]]\n",
    "        train_df, val_df = discourse_df[discourse_df[\"kfold\"] != f], discourse_df[discourse_df[\"kfold\"] == f]\n",
    "\n",
    "        d_train = xgb.DMatrix(train_df[features], train_df[target])\n",
    "        d_val = xgb.DMatrix(val_df[features], val_df[target])\n",
    "\n",
    "        model = xgb.train(xgb_param, d_train, evals=[(d_val, \"val\")], num_boost_round=2000, verbose_eval=200, \n",
    "                          early_stopping_rounds=50)\n",
    "        model.save_model(f'gbm_models/xgb_{dtype}_{f}.json')\n",
    "\n",
    "        y_oof[val_ind] = 0.5*model.predict(d_val)\n",
    "        best_its.append(model.best_iteration)\n",
    "\n",
    "\n",
    "        lgb_train = lgb.Dataset(train_df[features].astype(\"float32\"), train_df[\"target\"].astype(\"float32\"))\n",
    "        lgb_val = lgb.Dataset(val_df[features].astype(\"float32\"), val_df[\"target\"].astype(\"float32\"))\n",
    "\n",
    "        model = lgb.train(lgb_param, lgb_train, num_boost_round=int(best_its[-1]*1.4), valid_sets=[lgb_val],\n",
    "                          verbose_eval=200)\n",
    "        model.save_model(f'gbm_models/lgb_{dtype}_{f}.txt')\n",
    "        y_oof[val_ind] += 0.5*model.predict(val_df[features].astype(\"float32\"))\n",
    "\n",
    "\n",
    "        print(\"...\")\n",
    "        \n",
    "    discourse_df[\"prob\"] = y_oof[all_indices]\n",
    "    discourse_df = discourse_df.sort_values([\"id\", \"prob\"], ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    print(\"removing overlaps...\")\n",
    "    \n",
    "    pred_df = []\n",
    "    prev_id = -1\n",
    "    overlap_array = np.zeros(4096)\n",
    "    for id, ps, cls, prob, overlap in zip(discourse_df[\"id\"].values, discourse_df[\"predictionstring\"].values,\n",
    "                                 discourse_df[\"class\"].values, discourse_df[\"prob\"].values,\n",
    "                                 discourse_df[\"overlap\"].values):\n",
    "        if id != prev_id:\n",
    "            prev_id = id\n",
    "            overlap_array = np.zeros(4096)\n",
    "        \n",
    "        ps_list = ps.split()\n",
    "        begin, end = int(ps_list[0]), int(ps_list[-1]) + 1\n",
    "        \n",
    "        intersect = np.sum(overlap_array[begin:end])\n",
    "        total = end - begin\n",
    "        \n",
    "        condition = intersect/total <= 0.15\n",
    "        \n",
    "        if condition:\n",
    "            pred_df.append({\"id\": id, \"class\": cls, \"prob\": prob, \"predictionstring\": ps, \"overlap\": overlap})\n",
    "            overlap_array[begin:end] = 1\n",
    "    \n",
    "    pred_df = pd.DataFrame(pred_df)\n",
    "    lvl1_stacking_df.append(pred_df)\n",
    "    print(\"tuning...\")\n",
    "    \n",
    "    thresholds = np.arange(10, 90, 1)/100\n",
    "    \n",
    "    all_gt = gt_df[gt_df[\"discourse_type\"] == dtype].shape[0]\n",
    "    print(pred_df.shape, all_gt)\n",
    "    f1s = []\n",
    "    for t in thresholds:\n",
    "        tp = (pred_df[pred_df[\"prob\"] > t][\"overlap\"] >= 0.5).sum()\n",
    "        fp = (pred_df[pred_df[\"prob\"] > t][\"overlap\"] < 0.5).sum()\n",
    "        fn = all_gt - tp\n",
    "        \n",
    "        f1 = tp / (tp + (fp + fn)/2)\n",
    "        \n",
    "        #print(t, tp, fp, fn)\n",
    "        \n",
    "        f1s.append(f1)\n",
    "\n",
    "    best_ind = np.argmax(f1s)\n",
    "    print()\n",
    "    print(thresholds[best_ind], f1s[best_ind])\n",
    "    print()\n",
    "    \n",
    "    best_th[dtype] = thresholds[best_ind]\n",
    "    res[dtype] = f1s\n",
    "    \n",
    "    \n",
    "    #d_train = xgb.DMatrix(discourse_df[features], discourse_df[target])\n",
    "    #model = xgb.train(param, d_train, num_boost_round=int(np.mean(best_its)*1.2))\n",
    "    #model.save_model(f'models/xgb_{dtype}.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "987a5842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Lead': 0.6,\n",
       " 'Position': 0.52,\n",
       " 'Evidence': 0.55,\n",
       " 'Claim': 0.55,\n",
       " 'Concluding Statement': 0.52,\n",
       " 'Counterclaim': 0.69,\n",
       " 'Rebuttal': 0.71}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd683419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Lead': 0.8668202643274835,\n",
       " 'Position': 0.7507901765078955,\n",
       " 'Evidence': 0.7594494276051763,\n",
       " 'Claim': 0.6665954187497375,\n",
       " 'Concluding Statement': 0.8681841708758448,\n",
       " 'Counterclaim': 0.5529634160161236,\n",
       " 'Rebuttal': 0.4623768075463306}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: np.mean(v) for k, v in res.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f53119f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199404, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lvl1_stacking_df = pd.concat(lvl1_stacking_df)\n",
    "lvl1_stacking_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07d439cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7317220596619645,\n",
       " {'Claim': 0.6898807468053553,\n",
       "  'Concluding Statement': 0.878745490686888,\n",
       "  'Counterclaim': 0.6028159221275856,\n",
       "  'Evidence': 0.7799607733258616,\n",
       "  'Lead': 0.875086634323186,\n",
       "  'Position': 0.7641899718682773,\n",
       "  'Rebuttal': 0.5313748784965979})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_feedback_comp(lvl1_stacking_df[lvl1_stacking_df[\"prob\"] > lvl1_stacking_df[\"class\"].map(best_th)], \n",
    "                    gt_df, return_class_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb80e916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15594"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oof_df[\"id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1e89bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15594"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gt_df[\"id\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95f5f8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lvl1_stacking_df.to_parquet(\"gbm_models/level1_oof.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "504395c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>class</th>\n",
       "      <th>prob</th>\n",
       "      <th>predictionstring</th>\n",
       "      <th>overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41518</th>\n",
       "      <td>4DA58F8F319A</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>215</td>\n",
       "      <td>0.002950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53201</th>\n",
       "      <td>1BA91BC3D89A</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>631</td>\n",
       "      <td>0.004878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5913</th>\n",
       "      <td>A3E66DCF8B6E</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>270</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18548</th>\n",
       "      <td>B0C685E8EA1A</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>469</td>\n",
       "      <td>0.014925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7110</th>\n",
       "      <td>E1DA1E513BE1</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>73</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6487</th>\n",
       "      <td>9AEE597CBE7E</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>0.998990</td>\n",
       "      <td>377 378 379 380 381 382 383 384 385 386 387 38...</td>\n",
       "      <td>0.883117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8421</th>\n",
       "      <td>7D92AFA8EB0C</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>0.999014</td>\n",
       "      <td>275 276 277 278 279 280 281 282 283 284 285 28...</td>\n",
       "      <td>0.873239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3347</th>\n",
       "      <td>CBA185D3B277</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>0.999021</td>\n",
       "      <td>282 283 284 285 286 287 288 289 290 291 292 29...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4223</th>\n",
       "      <td>BDE4475D7290</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>0.999104</td>\n",
       "      <td>292 293 294 295 296 297 298 299 300 301 302 30...</td>\n",
       "      <td>0.987805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>64246ED6F213</td>\n",
       "      <td>Concluding Statement</td>\n",
       "      <td>0.999187</td>\n",
       "      <td>344 345 346 347 348 349 350 351 352 353 354 35...</td>\n",
       "      <td>0.939394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199404 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                 class      prob  \\\n",
       "41518  4DA58F8F319A              Evidence  0.000026   \n",
       "53201  1BA91BC3D89A              Evidence  0.000040   \n",
       "5913   A3E66DCF8B6E  Concluding Statement  0.000046   \n",
       "18548  B0C685E8EA1A              Evidence  0.000047   \n",
       "7110   E1DA1E513BE1              Evidence  0.000050   \n",
       "...             ...                   ...       ...   \n",
       "6487   9AEE597CBE7E  Concluding Statement  0.998990   \n",
       "8421   7D92AFA8EB0C  Concluding Statement  0.999014   \n",
       "3347   CBA185D3B277  Concluding Statement  0.999021   \n",
       "4223   BDE4475D7290  Concluding Statement  0.999104   \n",
       "9999   64246ED6F213  Concluding Statement  0.999187   \n",
       "\n",
       "                                        predictionstring   overlap  \n",
       "41518                                                215  0.002950  \n",
       "53201                                                631  0.004878  \n",
       "5913                                                 270  0.000000  \n",
       "18548                                                469  0.014925  \n",
       "7110                                                  73  0.000000  \n",
       "...                                                  ...       ...  \n",
       "6487   377 378 379 380 381 382 383 384 385 386 387 38...  0.883117  \n",
       "8421   275 276 277 278 279 280 281 282 283 284 285 28...  0.873239  \n",
       "3347   282 283 284 285 286 287 288 289 290 291 292 29...  1.000000  \n",
       "4223   292 293 294 295 296 297 298 299 300 301 302 30...  0.987805  \n",
       "9999   344 345 346 347 348 349 350 351 352 353 354 35...  0.939394  \n",
       "\n",
       "[199404 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lvl1_stacking_df.sort_values(\"prob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc0a18f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='threshold'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "th_df = pd.DataFrame()\n",
    "\n",
    "for k, v in res.items():\n",
    "    th_df[k] = v\n",
    "    \n",
    "th_df[\"threshold\"] = np.arange(10, 90, 1)/100\n",
    "\n",
    "th_df.plot(figsize=(12, 12), x=\"threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a55063a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
